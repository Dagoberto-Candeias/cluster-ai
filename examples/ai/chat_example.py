#!/usr/bin/env python3
"""
Exemplo PrÃ¡tico: Chat com Modelos de IA no Cluster AI
====================================================

Este exemplo demonstra como usar modelos de linguagem avanÃ§ados (Llama, Mistral, etc.)
atravÃ©s do Ollama no Cluster AI para tarefas de conversaÃ§Ã£o inteligente.

PrÃ©-requisitos:
- Cluster AI instalado e rodando
- Pelo menos um modelo baixado (ex: llama3:8b, mistral:7b)

Uso:
    python chat_example.py [--model nome_do_modelo] [--interactive]
"""

import argparse
import json
import time
from typing import List, Dict, Any
from ollama import Client
from dask.distributed import Client as DaskClient


class AIChatAssistant:
    """Assistente de chat inteligente usando modelos Ollama."""

    def __init__(
        self, model_name: str = "llama3:8b", host: str = "http://localhost:11434"
    ):
        self.model_name = model_name
        self.client = Client(host=host)
        self.conversation_history: List[Dict[str, str]] = []

        # Verificar se o modelo estÃ¡ disponÃ­vel
        self._check_model_availability()

    def _check_model_availability(self):
        """Verifica se o modelo estÃ¡ disponÃ­vel localmente."""
        try:
            models = self.client.list()
            print(f"ğŸ” Resposta da API: {models}")  # Debug

            # Verificar estrutura da resposta
            if "models" not in models:
                print("âš ï¸  Estrutura de resposta inesperada da API Ollama")
                print(f"ğŸ“‹ Resposta completa: {models}")
                # Tentar usar modelo diretamente sem verificaÃ§Ã£o
                print(f"ğŸ”„ Tentando usar modelo '{self.model_name}' sem verificaÃ§Ã£o...")
                return

            available_models = []
            for model in models["models"]:
                # Model objects tÃªm atributo 'model' com o nome
                if hasattr(model, "model"):
                    model_name = model.model
                elif isinstance(model, dict):
                    model_name = model.get("name") or model.get("model") or str(model)
                else:
                    model_name = str(model)
                available_models.append(model_name)

            print(f"ğŸ“‹ Modelos encontrados: {available_models}")

            if self.model_name not in available_models:
                print(f"âš ï¸  Modelo '{self.model_name}' nÃ£o encontrado localmente.")
                print(f"ğŸ“‹ Modelos disponÃ­veis: {', '.join(available_models[:5])}")
                if available_models:
                    self.model_name = available_models[0]
                    print(f"ğŸ”„ Usando modelo alternativo: {self.model_name}")
                else:
                    raise ValueError(
                        "Nenhum modelo encontrado. Execute: ollama pull llama3:8b"
                    )
            else:
                print(f"âœ… Modelo '{self.model_name}' carregado com sucesso!")

        except Exception as e:
            print(f"âŒ Erro ao verificar modelos: {e}")
            print("ğŸ”„ Continuando sem verificaÃ§Ã£o de modelos...")
            # NÃ£o lanÃ§ar erro, permitir que o usuÃ¡rio tente usar o modelo

    def chat(self, message: str, system_prompt: str | None = None) -> str:
        """Envia uma mensagem para o modelo e retorna a resposta."""
        # Preparar mensagens
        messages = []

        # Adicionar prompt do sistema se fornecido
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})

        # Adicionar histÃ³rico da conversa
        messages.extend(self.conversation_history)

        # Adicionar mensagem atual
        messages.append({"role": "user", "content": message})

        try:
            start_time = time.time()

            # Fazer a chamada para o modelo
            response = self.client.chat(
                model=self.model_name,
                messages=messages,
                options={"temperature": 0.7, "top_p": 0.9, "num_predict": 1024},
            )

            response_time = time.time() - start_time
            ai_response = response["message"]["content"]

            # Adicionar ao histÃ³rico
            self.conversation_history.append({"role": "user", "content": message})
            self.conversation_history.append(
                {"role": "assistant", "content": ai_response}
            )

            # Manter histÃ³rico limitado
            if len(self.conversation_history) > 20:
                self.conversation_history = self.conversation_history[-20:]

            print(".2f")
            return ai_response

        except Exception as e:
            error_msg = f"Erro na comunicaÃ§Ã£o com o modelo: {e}"
            print(f"âŒ {error_msg}")
            return error_msg

    def analyze_text(self, text: str, task: str) -> Dict[str, Any]:
        """AnÃ¡lise avanÃ§ada de texto usando o modelo."""
        system_prompt = f"""VocÃª Ã© um assistente especializado em {task}.
        ForneÃ§a uma anÃ¡lise detalhada e estruturada do texto fornecido.
        Organize sua resposta em seÃ§Ãµes claras com headers descritivos."""

        prompt = f"""
        Texto para anÃ¡lise:
        ---
        {text}
        ---

        Tarefa: {task}

        Por favor, forneÃ§a:
        1. Resumo executivo
        2. AnÃ¡lise detalhada
        3. Insights principais
        4. RecomendaÃ§Ãµes (se aplicÃ¡vel)
        """

        response = self.chat(prompt, system_prompt)

        return {
            "task": task,
            "text_length": len(text),
            "analysis": response,
            "model_used": self.model_name,
            "timestamp": time.time(),
        }

    def generate_code(self, requirement: str, language: str = "python") -> str:
        """Gera cÃ³digo baseado em requisitos."""
        system_prompt = f"""VocÃª Ã© um programador especialista em {language}.
        ForneÃ§a cÃ³digo limpo, bem documentado e seguindo as melhores prÃ¡ticas."""

        prompt = f"""
        Gere cÃ³digo {language} para o seguinte requisito:

        {requirement}

        Inclua:
        - ComentÃ¡rios explicativos
        - Tratamento de erros
        - Exemplos de uso
        - DocumentaÃ§Ã£o das funÃ§Ãµes
        """

        return self.chat(prompt, system_prompt)

    def translate_text(
        self, text: str, target_language: str, source_language: str = "auto"
    ) -> str:
        """Traduz texto para outro idioma."""
        system_prompt = (
            "VocÃª Ã© um tradutor profissional. ForneÃ§a traduÃ§Ãµes precisas e naturais."
        )

        if source_language == "auto":
            source_language = "portuguÃªs"

        prompt = f"""
        Traduza o seguinte texto do {source_language} para {target_language}:

        Texto original:
        {text}

        ForneÃ§a apenas a traduÃ§Ã£o, sem explicaÃ§Ãµes adicionais.
        """

        return self.chat(prompt, system_prompt)

    def clear_history(self):
        """Limpa o histÃ³rico da conversa."""
        self.conversation_history.clear()
        print("ğŸ§¹ HistÃ³rico da conversa limpo!")

    def get_conversation_stats(self) -> Dict[str, Any]:
        """Retorna estatÃ­sticas da conversa atual."""
        user_messages = len(
            [msg for msg in self.conversation_history if msg["role"] == "user"]
        )
        assistant_messages = len(
            [msg for msg in self.conversation_history if msg["role"] == "assistant"]
        )

        total_chars = sum(len(msg["content"]) for msg in self.conversation_history)

        return {
            "total_messages": len(self.conversation_history),
            "user_messages": user_messages,
            "assistant_messages": assistant_messages,
            "total_characters": total_chars,
            "model": self.model_name,
        }


def interactive_chat(assistant: AIChatAssistant):
    """Interface de chat interativo."""
    print("ğŸ¤– Chat Interativo com Cluster AI")
    print("=" * 50)
    print(f"ğŸ“š Modelo: {assistant.model_name}")
    print("ğŸ’¡ Comandos especiais:")
    print("  /clear - Limpar histÃ³rico")
    print("  /stats - Ver estatÃ­sticas")
    print("  /analyze [tarefa] - AnÃ¡lise de texto")
    print("  /code [linguagem] - Gerar cÃ³digo")
    print("  /translate [idioma] - Traduzir texto")
    print("  /quit - Sair")
    print("=" * 50)

    while True:
        try:
            user_input = input("\nğŸ‘¤ VocÃª: ").strip()

            if not user_input:
                continue

            if user_input.lower() in ["/quit", "quit", "sair", "exit"]:
                print("ğŸ‘‹ AtÃ© logo!")
                break

            elif user_input.lower() == "/clear":
                assistant.clear_history()

            elif user_input.lower() == "/stats":
                stats = assistant.get_conversation_stats()
                print("\nğŸ“Š EstatÃ­sticas da Conversa:")
                print(f"   â€¢ Total de mensagens: {stats['total_messages']}")
                print(f"   â€¢ Suas mensagens: {stats['user_messages']}")
                print(f"   â€¢ Respostas do AI: {stats['assistant_messages']}")
                print(f"   â€¢ Total de caracteres: {stats['total_characters']:,}")

            elif user_input.lower().startswith("/analyze "):
                task = user_input[9:].strip()
                if not task:
                    print("âŒ Especifique a tarefa. Exemplo: /analyze resumir texto")
                    continue

                text = input("ğŸ“„ Texto para analisar: ").strip()
                if not text:
                    print("âŒ Texto nÃ£o pode estar vazio.")
                    continue

                print("\nğŸ” Analisando...")
                result = assistant.analyze_text(text, task)
                print(f"\nğŸ“‹ AnÃ¡lise ({task}):")
                print(result["analysis"])

            elif user_input.lower().startswith("/code "):
                lang = user_input[6:].strip() or "python"
                requirement = input(f"ğŸ“ Requisito para cÃ³digo {lang}: ").strip()
                if not requirement:
                    print("âŒ Requisito nÃ£o pode estar vazio.")
                    continue

                print(f"\nğŸ’» Gerando cÃ³digo {lang}...")
                code = assistant.generate_code(requirement, lang)
                print(f"\n``` {lang}")
                print(code)
                print("```")

            elif user_input.lower().startswith("/translate "):
                target_lang = user_input[11:].strip()
                if not target_lang:
                    print("âŒ Especifique o idioma. Exemplo: /translate inglÃªs")
                    continue

                text = input("ğŸ“„ Texto para traduzir: ").strip()
                if not text:
                    print("âŒ Texto nÃ£o pode estar vazio.")
                    continue

                print(f"\nğŸŒ Traduzindo para {target_lang}...")
                translation = assistant.translate_text(text, target_lang)
                print(f"\nğŸ“‹ TraduÃ§Ã£o ({target_lang}):")
                print(translation)

            else:
                # Chat normal
                print("\nğŸ¤– AI:")
                response = assistant.chat(user_input)
                print(response)

        except KeyboardInterrupt:
            print("\nğŸ‘‹ Chat interrompido pelo usuÃ¡rio!")
            break
        except Exception as e:
            print(f"âŒ Erro: {e}")


def demo_examples(assistant: AIChatAssistant):
    """Demonstra vÃ¡rios recursos do assistente."""
    print("ğŸš€ DemonstraÃ§Ã£o dos Recursos do Cluster AI")
    print("=" * 60)

    # Exemplo 1: Chat simples
    print("\n1ï¸âƒ£ Chat Simples:")
    response = assistant.chat("OlÃ¡! Explique o que Ã© machine learning em uma frase.")
    print(f"ğŸ¤– {response}")

    # Exemplo 2: AnÃ¡lise de texto
    print("\n2ï¸âƒ£ AnÃ¡lise de Sentimentos:")
    text = (
        "Este produto Ã© incrÃ­vel! Funciona perfeitamente e superou minhas expectativas."
    )
    analysis = assistant.analyze_text(text, "anÃ¡lise de sentimentos")
    print(f"ğŸ“„ Texto: {text}")
    print(f"ğŸ” AnÃ¡lise: {analysis['analysis'][:200]}...")

    # Exemplo 3: GeraÃ§Ã£o de cÃ³digo
    print("\n3ï¸âƒ£ GeraÃ§Ã£o de CÃ³digo:")
    code = assistant.generate_code(
        "Criar uma funÃ§Ã£o que calcula a mÃ©dia de uma lista de nÃºmeros", "python"
    )
    print("```python")
    print(code[:300] + "..." if len(code) > 300 else code)
    print("```")

    # Exemplo 4: TraduÃ§Ã£o
    print("\n4ï¸âƒ£ TraduÃ§Ã£o:")
    translation = assistant.translate_text("Hello, how are you?", "portuguÃªs")
    print(f"ğŸ‡ºğŸ‡¸ Hello, how are you? â†’ ğŸ‡§ğŸ‡· {translation}")

    # EstatÃ­sticas finais
    print("\nğŸ“Š EstatÃ­sticas da DemonstraÃ§Ã£o:")
    stats = assistant.get_conversation_stats()
    for key, value in stats.items():
        print(f"   â€¢ {key}: {value}")


def main():
    parser = argparse.ArgumentParser(description="Chat com IA no Cluster AI")
    parser.add_argument(
        "--model",
        "-m",
        default="llama3:8b",
        help="Nome do modelo Ollama (padrÃ£o: llama3:8b)",
    )
    parser.add_argument(
        "--interactive", "-i", action="store_true", help="Modo interativo de chat"
    )
    parser.add_argument(
        "--demo", "-d", action="store_true", help="Executar demonstraÃ§Ã£o dos recursos"
    )
    parser.add_argument(
        "--host", default="http://localhost:11434", help="Host do servidor Ollama"
    )

    args = parser.parse_args()

    print("ğŸš€ Cluster AI - Chat com IA")
    print("=" * 40)

    try:
        # Inicializar assistente
        assistant = AIChatAssistant(args.model, args.host)

        if args.demo:
            # Executar demonstraÃ§Ã£o
            demo_examples(assistant)
        elif args.interactive:
            # Modo interativo
            interactive_chat(assistant)
        else:
            # Chat simples
            print("ğŸ’¡ Modo simples - Digite sua mensagem:")
            while True:
                try:
                    message = input("\nğŸ‘¤ VocÃª: ").strip()
                    if message.lower() in ["quit", "sair", "exit"]:
                        break
                    if message:
                        response = assistant.chat(message)
                        print(f"\nğŸ¤– AI: {response}")
                except KeyboardInterrupt:
                    break

        print("\nâœ… SessÃ£o finalizada!")

    except Exception as e:
        print(f"âŒ Erro: {e}")
        print("\nğŸ’¡ Dicas para soluÃ§Ã£o:")
        print("   â€¢ Verifique se o Cluster AI estÃ¡ rodando: ./manager.sh")
        print("   â€¢ Baixe um modelo: ollama pull llama3:8b")
        print("   â€¢ Verifique a conexÃ£o: curl http://localhost:11434/api/tags")


if __name__ == "__main__":
    main()
