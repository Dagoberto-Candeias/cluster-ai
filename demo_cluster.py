#!/usr/bin/env python3
# Local: demo_cluster.py
# Autor: Dagoberto Candeias <betoallnet@gmail.com>
"""
Demonstraﾃｧﾃ｣o do Cluster AI - Processamento Distribuﾃｭdo com Dask

Este script demonstra o funcionamento bﾃ｡sico de um cluster Dask
com processamento distribuﾃｭdo de tarefas.
"""

import time
import numpy as np
import dask
from dask.distributed import Client, LocalCluster
import logging

# Configurar logging
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


def processamento_pesado(x):
    """Funﾃｧﾃ｣o que simula processamento intensivo de CPU"""
    logger.info(f"Processando elemento {x}")
    time.sleep(0.1)  # Simula processamento
    return x * x


def calcular_fibonacci(n):
    """Calcula Fibonacci de forma recursiva (intensiva em CPU)"""
    if n < 0:
        raise ValueError("Fibonacci nﾃ｣o estﾃ｡ definido para nﾃｺmeros negativos")
    if n <= 1:
        return n
    return calcular_fibonacci(n - 1) + calcular_fibonacci(n - 2)


def process_with_dask(client, numbers, operation):
    """
    Processa uma lista de nﾃｺmeros usando uma operaﾃｧﾃ｣o distribuﾃｭda com Dask

    Args:
        client: Cliente Dask
        numbers: Lista de nﾃｺmeros para processar
        operation: Funﾃｧﾃ｣o a ser aplicada a cada nﾃｺmero

    Returns:
        Lista com os resultados processados
    """
    if not numbers:
        return []

    # Submeter tarefas para processamento distribuﾃｭdo
    futures = [client.submit(operation, num) for num in numbers]

    # Coletar resultados
    results = client.gather(futures)

    return results


def create_cluster():
    """
    Cria um cluster Dask local e retorna cluster e cliente

    Returns:
        tuple: (cluster, client) - Instﾃ｢ncias do cluster e cliente Dask
    """
    cluster = LocalCluster(n_workers=2, threads_per_worker=2, processes=False)
    client = Client(cluster)
    return cluster, client


def demo_basica():
    """Demonstraﾃｧﾃ｣o bﾃ｡sica do Dask"""
    logger.info("=== DEMONSTRAﾃﾃグ BﾃヾICA DASK ===")

    # Criar um cluster local
    cluster = LocalCluster(n_workers=2, threads_per_worker=2)
    client = Client(cluster)
    try:
        logger.info(f"Cluster criado: {cluster}")
        logger.info(f"Dashboard disponﾃｭvel em: {cluster.dashboard_link}")

        # Criar uma lista de tarefas
        dados = list(range(20))
        logger.info(f"Processando {len(dados)} elementos...")

        # Processar em paralelo
        inicio = time.time()
        resultados = client.map(processamento_pesado, dados)
        resultados = client.gather(resultados)
        fim = time.time()

        logger.info(f"Resultados: {resultados}")
        logger.info(f"Tempo total: {fim - inicio:.2f} segundos")

        return resultados
    finally:
        client.close()
        cluster.close()


def demo_avancada():
    """Demonstraﾃｧﾃ｣o avanﾃｧada com computaﾃｧﾃ｣o distribuﾃｭda"""
    logger.info("\n=== DEMONSTRAﾃﾃグ AVANﾃ②DA ===")

    try:
        with LocalCluster(n_workers=4, threads_per_worker=1) as cluster:
            with Client(cluster) as client:
                logger.info(f"Cluster avanﾃｧado criado: {cluster}")

                # Calcular Fibonacci para vﾃ｡rios nﾃｺmeros em paralelo
                numeros = [30, 31, 32, 33, 34]
                logger.info(f"Calculando Fibonacci para: {numeros}")

                inicio = time.time()
                futuros = [client.submit(calcular_fibonacci, n) for n in numeros]
                resultados = list(client.gather(futuros))  # type: ignore
                fim = time.time()

                for n, resultado in zip(numeros, resultados):
                    logger.info(f"Fibonacci({n}) = {resultado}")

                logger.info(f"Tempo paralelo: {fim - inicio:.2f} segundos")

                # Comparar com tempo sequencial
                inicio_seq = time.time()
                resultados_seq = [calcular_fibonacci(n) for n in numeros]
                fim_seq = time.time()

                logger.info(f"Tempo sequencial: {fim_seq - inicio_seq:.2f} segundos")
                logger.info(f"Speedup: {(fim_seq - inicio_seq) / (fim - inicio):.2f}x")

                return {
                    "status": "success",
                    "results": resultados,
                    "computation_time": fim - inicio,
                }
    except Exception as e:
        logger.error(f"Erro na demonstraﾃｧﾃ｣o avanﾃｧada: {e}")
        return {"status": "error", "error": str(e)}


def demo_data_science():
    """Demonstraﾃｧﾃ｣o com operaﾃｧﾃｵes de data science"""
    logger.info("\n=== DEMONSTRAﾃﾃグ DATA SCIENCE ===")

    with LocalCluster() as cluster:
        with Client(cluster) as client:
            logger.info("Processamento de dados com Dask Arrays")

            # Criar um array grande distribuﾃｭdo
            import dask.array as da

            array_grande = da.random.random((10000, 10000), chunks=(1000, 1000))
            logger.info(f"Array criado: {array_grande}")

            # Operaﾃｧﾃｵes distribuﾃｭdas
            media = array_grande.mean()
            std = array_grande.std()
            soma = array_grande.sum()

            logger.info(f"Mﾃｩdia: {media.compute()}")
            logger.info(f"Desvio padrﾃ｣o: {std.compute():.4f}")
            logger.info(f"Soma: {soma.compute():.4f}")


def main():
    """Funﾃｧﾃ｣o principal"""
    logger.info("噫 INICIANDO DEMONSTRAﾃﾃグ DO CLUSTER AI 噫")
    logger.info("=" * 50)

    try:
        # Demo bﾃ｡sica
        demo_basica()

        # Demo avanﾃｧada
        demo_avancada()

        # Demo data science
        demo_data_science()

        logger.info("\n笨 DEMONSTRAﾃﾃグ CONCLUﾃ好A COM SUCESSO!")
        logger.info("O cluster Dask estﾃ｡ funcionando perfeitamente!")

    except Exception as e:
        logger.error(f"Erro durante a demonstraﾃｧﾃ｣o: {e}")
        return 1

    return 0


if __name__ == "__main__":
    exit(main())
