# üìñ Manual do OpenWebUI - Interface Web para Ollama

## üéØ Vis√£o Geral

O OpenWebUI √© uma interface web de c√≥digo aberto projetada para interagir com modelos de linguagem executados localmente atrav√©s do Ollama. Esta interface oferece uma experi√™ncia de usu√°rio moderna e intuitiva para trabalhar com modelos de IA.

## üöÄ Instala√ß√£o e Configura√ß√£o

### Instala√ß√£o Autom√°tica
O OpenWebUI √© instalado automaticamente quando voc√™ configura uma m√°quina como **Servidor Principal** ou **Esta√ß√£o de Trabalho** usando o script de instala√ß√£o do Cluster AI.

```bash
./install_cluster.sh --role server
```

### Instala√ß√£o Manual
```bash
# Usando Docker (recomendado)
docker run -d --name open-webui \
  -p 8080:8080 \
  -v open-webui:/app/backend/data \
  -e OLLAMA_BASE_URL=http://host.docker.internal:11434 \
  --add-host=host.docker.internal:host-gateway \
  ghcr.io/open-webui/open-webui:main

# Ou usando Docker Compose
docker-compose -f configs/docker/compose-basic.yml up -d
```

## ‚öôÔ∏è Configura√ß√£o

### Vari√°veis de Ambiente
| Vari√°vel | Descri√ß√£o | Valor Padr√£o |
|----------|-----------|-------------|
| `OLLAMA_BASE_URL` | URL da API do Ollama | `http://localhost:11434` |
| `WEBUI_PORT` | Porta do OpenWebUI | `8080` |
| `DATA_DIR` | Diret√≥rio de dados | `/app/data` |

### Configura√ß√£o com TLS (Produ√ß√£o)
Para configura√ß√£o segura em produ√ß√£o, use o arquivo `docker-compose-tls.yml`:

```bash
cd configs/docker
docker-compose -f compose-tls.yml up -d
```

## üåê Acesso e Uso

### Primeiro Acesso
1. Abra seu navegador e acesse: `http://localhost:8080`
2. Crie uma conta de administrador
3. Configure as prefer√™ncias iniciais

### Funcionalidades Principais

#### üí¨ Chat com Modelos
- Interface de chat intuitiva
- Suporte a m√∫ltiplos modelos
- Hist√≥rico de conversas
- Exporta√ß√£o de conversas

#### ‚öôÔ∏è Gerenciamento de Modelos
- Lista de modelos dispon√≠veis
- Download de novos modelos
- Configura√ß√£o de par√¢metros

#### üë• Gerenciamento de Usu√°rios
- Sistema de autentica√ß√£o
- Controle de permiss√µes
- Logs de atividade

## üîß Configura√ß√£o Avan√ßada

### Integra√ß√£o com Ollama
Certifique-se de que o Ollama est√° configurado para aceitar conex√µes externas:

```bash
# Configurar Ollama para escutar em todas as interfaces
export OLLAMA_HOST=0.0.0.0
ollama serve
```

### Configura√ß√£o de Proxy Reverso (Nginx)
Exemplo de configura√ß√£o Nginx:

```nginx
server {
    listen 80;
    server_name seu-dominio.com;
    
    location / {
        proxy_pass http://localhost:8080;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
}
```

### Configura√ß√£o com TLS
Use o script de certificados Let's Encrypt:

```bash
./configs/tls/issue-certs-robust.sh seu-dominio.com seu-email@exemplo.com
```

## üõ†Ô∏è Solu√ß√£o de Problemas

### Problemas Comuns

#### ‚ùå OpenWebUI n√£o consegue conectar ao Ollama
**Solu√ß√£o:**
```bash
# Verificar se Ollama est√° rodando
curl http://localhost:11434/api/tags

# Configurar Ollama para aceitar conex√µes externas
export OLLAMA_HOST=0.0.0.0
sudo systemctl restart ollama
```

#### ‚ùå Erro de permiss√£o no Docker
**Solu√ß√£o:**
```bash
# Verificar permiss√µes do volume
sudo chown -R 1000:1000 /var/lib/docker/volumes/open-webui
```

#### ‚ùå Porta j√° em uso
**Solu√ß√£o:**
```bash
# Verificar processos usando a porta
sudo lsof -i :8080

# Matar processo conflitante ou mudar porta
docker run -p 8081:8080 ... 
```

### Logs e Diagn√≥stico

#### Verificar Logs do Container
```bash
docker logs open-webui
docker logs openwebui-nginx
```

#### Verificar Sa√∫de dos Servi√ßos
```bash
# Verificar se OpenWebUI est√° respondendo
curl http://localhost:8080/api/health

# Verificar conex√£o com Ollama
curl http://localhost:11434/api/tags
```

## üîí Seguran√ßa

### Melhores Pr√°ticas de Seguran√ßa

1. **Use HTTPS em produ√ß√£o**
2. **Configure firewall adequadamente**
3. **Mantenha software atualizado**
4. **Use autentica√ß√£o forte**
5. **Monitore logs regularmente**

### Configura√ß√£o de Firewall
```bash
# Permitir apenas portas necess√°rias
sudo ufw allow 22/tcp    # SSH
sudo ufw allow 8080/tcp  # OpenWebUI
sudo ufw allow 11434/tcp # Ollama
sudo ufw enable
```

## üìä Monitoramento e Manuten√ß√£o

### Backup de Dados
```bash
# Fazer backup dos dados do OpenWebUI
tar -czf openwebui-backup-$(date +%Y%m%d).tar.gz \
  /var/lib/docker/volumes/open-webui
```

### Atualiza√ß√£o
```bash
# Parar containers
docker-compose down

# Pull da imagem mais recente
docker pull ghcr.io/open-webui/open-webui:main

# Reiniciar containers
docker-compose up -d
```

### Limpeza de Dados
```bash
# Limpar conversas antigas (via interface web)
# Ou manualmente via banco de dados
```

## üéØ Exemplos de Uso

### Uso B√°sico
1. Acesse `http://localhost:8080`
2. Selecione um modelo (ex: llama3)
3. Comece a conversar!

### Uso Avan√ßado com API
```python
import requests

# Enviar mensagem para o OpenWebUI
response = requests.post(
    'http://localhost:8080/api/chat',
    json={
        'model': 'llama3',
        'messages': [{'role': 'user', 'content': 'Ol√°!'}]
    }
)
```

### Integra√ß√£o com Outras Ferramentas
```bash
# Usar curl para interagir com a API
curl -X POST http://localhost:8080/api/chat \
  -H "Content-Type: application/json" \
  -d '{"model": "llama3", "messages": [{"role": "user", "content": "Explique AI"}]}'
```

## üìà Otimiza√ß√£o de Performance

### Configura√ß√£o para Alta Demanda
```yaml
# docker-compose.yml otimizado
services:
  open-webui:
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2'
    environment:
      - WORKER_COUNT=4
      - MAX_REQUEST_SIZE=100MB
```

### Monitoramento de Performance
```bash
# Verificar uso de recursos
docker stats open-webui

# Monitorar logs em tempo real
docker logs -f open-webui
```

## ü§ù Suporte e Comunidade

### Recursos √öteis
- **[Documenta√ß√£o Oficial](https://docs.openwebui.com/)**
- **[GitHub Repository](https://github.com/open-webui/open-webui)**
- **[Discord Community](https://discord.gg/openwebui)**

### Reportar Problemas
1. Verifique logs primeiro
2. Consulte a documenta√ß√£o
3. Procure issues existentes no GitHub
4. Crie novo issue com informa√ß√µes detalhadas

## üìù Changelog

### Vers√£o 1.0
- ‚úÖ Instala√ß√£o b√°sica funcionando
- ‚úÖ Integra√ß√£o com Ollama
- ‚úÖ Interface web moderna
- ‚úÖ Sistema de autentica√ß√£o

### Pr√≥ximas Vers√µes
- [ ] Suporte a m√∫ltiplos usu√°rios avan√ßado
- [ ] Plugins e extens√µes
- [ ] API mais robusta
- [ ] Melhorias de performance

---

**üí° Dica**: Para come√ßar rapidamente, execute o script de instala√ß√£o do Cluster AI que configura automaticamente o OpenWebUI junto com todos os outros componentes necess√°rios.

**üìû Suporte**: Em caso de problemas, consulte a documenta√ß√£o oficial ou abra uma issue no GitHub do projeto.
