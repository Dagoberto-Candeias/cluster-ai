# üöÄ Guia de Otimiza√ß√£o de Performance - Cluster AI

## üìã Vis√£o Geral

Este guia apresenta t√©cnicas avan√ßadas para otimizar o desempenho do Cluster AI, incluindo configura√ß√µes do sistema, otimiza√ß√£o de scripts e melhores pr√°ticas para processamento distribu√≠do.

## üõ†Ô∏è Ferramentas de Otimiza√ß√£o

### Otimizador de Performance

O script principal de otimiza√ß√£o √© `scripts/optimization/performance_optimizer.sh`. Ele automatiza v√°rias otimiza√ß√µes para melhorar o desempenho geral do sistema.

### Funcionalidades do Otimizador

- **Otimiza√ß√£o de Scripts Bash**: Paraleliza√ß√£o de downloads, timeouts, tratamento de erros
- **Cache de Pacotes**: Configura√ß√£o otimizada para diferentes distribui√ß√µes Linux
- **Configura√ß√µes do Sistema**: Limites de arquivos, configura√ß√µes de kernel
- **Otimiza√ß√£o Docker**: Configura√ß√µes de logging, storage driver, ulimits
- **Otimiza√ß√£o Python/Pip**: Cache, timeouts, mirrors
- **Benchmark**: Medi√ß√£o de performance dos scripts principais

## üöÄ Como Usar o Otimizador

### Execu√ß√£o B√°sica

```bash
# Executar todas as otimiza√ß√µes
./scripts/optimization/performance_optimizer.sh

# Verificar melhorias
./scripts/utils/health_check.sh
```

### O que o Otimizador Faz

1. **Scripts Bash**
   - Adiciona paraleliza√ß√£o para downloads
   - Configura timeouts para comandos lentos
   - Otimiza loops e condi√ß√µes
   - Melhora tratamento de erros

2. **Cache de Pacotes**
   - Limpa cache antigo
   - Configura reposit√≥rios otimizados
   - Suporte para Ubuntu/Debian, Arch/Manjaro, Fedora/CentOS

3. **Sistema Operacional**
   - Aumenta limites de arquivos abertos (65536)
   - Otimiza configura√ß√µes de kernel
   - Reduz swappiness para 10
   - Aumenta somaxconn para 65535

4. **Docker**
   - Configura storage driver overlay2
   - Otimiza logging (100MB max, 3 arquivos)
   - Aumenta ulimits para arquivos

5. **Python/Pip**
   - Configura cache pip
   - Adiciona timeouts e retries
   - Configura mirrors (PyPI, NGC, PyTorch)

## üìä Benchmark de Performance

O otimizador inclui um sistema de benchmark que mede o tempo de execu√ß√£o dos scripts principais:

```json
{
  "timestamp": "2024-01-15T10:30:00+00:00",
  "benchmarks": {
    "install_universal.sh": 2.345,
    "scripts/utils/health_check.sh": 0.123,
    "scripts/utils/check_models.sh": 1.567
  }
}
```

## ‚ö° Otimiza√ß√µes Manuais Avan√ßadas

### Configura√ß√µes de Kernel

```bash
# Arquivo /etc/sysctl.conf
vm.swappiness=10
vm.vfs_cache_pressure=50
net.core.somaxconn=65535
net.ipv4.tcp_max_syn_backlog=65535
```

### Limites do Sistema

```bash
# Arquivo /etc/security/limits.conf
* soft nofile 65536
* hard nofile 131072
* soft nproc 65536
* hard nproc 131072
```

### Docker Otimizado

```json
{
    "log-driver": "json-file",
    "log-opts": {
        "max-size": "100m",
        "max-file": "3"
    },
    "storage-driver": "overlay2",
    "storage-opts": [
        "overlay2.override_kernel_check=true"
    ],
    "default-ulimits": {
        "nofile": {
            "Name": "nofile",
            "Hard": 65536,
            "Soft": 65536
        }
    }
}
```

## üéØ Otimiza√ß√µes por Componente

### Dask Cluster

```python
# Configura√ß√µes otimizadas para Dask
import dask
from dask.distributed import Client, LocalCluster

# Configura√ß√µes de performance
dask.config.set({
    'distributed.worker.memory.target': 0.6,  # 60% da mem√≥ria
    'distributed.worker.memory.spill': 0.7,   # Spill em 70%
    'distributed.worker.memory.pause': 0.8,   # Pause em 80%
    'distributed.worker.memory.terminate': 0.95,  # Terminate em 95%
    'distributed.comm.timeouts.connect': '10s',
    'distributed.comm.timeouts.tcp': '30s'
})

# Cluster local otimizado
cluster = LocalCluster(
    n_workers=4,
    threads_per_worker=2,
    memory_limit='2GB',
    processes=True,
    silence_logs=False
)
client = Client(cluster)
```

### Ollama

```bash
# Configura√ß√µes para GPU
export OLLAMA_GPU_LAYERS=35
export OLLAMA_MAX_LOADED_MODELS=2
export OLLAMA_NUM_THREAD=8

# Otimiza√ß√£o de mem√≥ria
export OLLAMA_MAX_MODEL_SIZE=8GB
```

### OpenWebUI

```bash
# Configura√ß√µes Docker otimizadas
docker run -d \
  --name open-webui \
  --restart unless-stopped \
  -p 8080:8080 \
  -v open-webui:/app/data \
  -e OLLAMA_BASE_URL=http://host.docker.internal:11434 \
  --memory=2g \
  --cpus=2 \
  ghcr.io/open-webui/open-webui:main
```

## üìà Monitoramento de Performance

### M√©tricas Principais

- **CPU**: Uso m√©dio, picos, temperatura
- **Mem√≥ria**: Uso total, swap, cache
- **Disco**: IOPS, lat√™ncia, espa√ßo livre
- **Rede**: Throughput, lat√™ncia, conex√µes
- **Dask**: Tarefas por segundo, tempo m√©dio, falhas
- **Ollama**: Tempo de infer√™ncia, uso de GPU
- **Docker**: Uso de recursos por container

### Ferramentas de Monitoramento

```bash
# Monitoramento em tempo real
htop
iotop
nvidia-smi
docker stats

# Scripts do Cluster AI
./scripts/monitoring/central_monitor.sh dashboard
./scripts/utils/health_check.sh
```

## üîß Troubleshooting de Performance

### Problemas Comuns

1. **CPU Alta**
   ```bash
   # Verificar processos
   ps aux --sort=-%cpu | head -10

   # Verificar load average
   uptime

   # Otimizar processos Python
   export OMP_NUM_THREADS=4
   export MKL_NUM_THREADS=4
   ```

2. **Mem√≥ria Insuficiente**
   ```bash
   # Verificar uso de mem√≥ria
   free -h
   vmstat 1

   # Configurar swap
   sudo fallocate -l 4G /swapfile
   sudo chmod 600 /swapfile
   sudo mkswap /swapfile
   sudo swapon /swapfile
   ```

3. **Disco Lento**
   ```bash
   # Verificar I/O
   iostat -x 1

   # Otimizar para SSD
   sudo systemctl enable fstrim.timer
   ```

4. **Rede Lenta**
   ```bash
   # Verificar conectividade
   ping -c 4 8.8.8.8
   traceroute google.com

   # Otimizar TCP
   sudo sysctl -w net.ipv4.tcp_congestion_control=bbr
   ```

## üìö Recomenda√ß√µes por Cen√°rio

### Para Desenvolvimento
- Use SSD para melhor I/O
- Configure 16GB+ RAM
- Use GPU dedicada se dispon√≠vel
- Otimize VSCode com extensions m√≠nimas

### Para Produ√ß√£o
- Use RAID 1 ou 10 para dados
- Configure 32GB+ RAM
- Use GPU com 8GB+ VRAM
- Configure backup autom√°tico
- Use monitoramento 24/7

### Para Clusters Grandes
- Use rede 10GbE
- Configure storage distribu√≠do
- Use load balancer
- Configure auto-scaling
- Use monitoramento centralizado

## üéØ Benchmarks de Refer√™ncia

### Tempos Esperados

- **Instala√ß√£o**: 5-15 minutos
- **Download de modelo (7B)**: 2-5 minutos
- **Infer√™ncia (100 tokens)**: 1-3 segundos
- **Processamento Dask**: 10-50% mais r√°pido que single-thread

### Configura√ß√µes de Refer√™ncia

```yaml
# cluster.conf otimizado
[system]
memory_target = 0.6
cpu_threads = 8
gpu_layers = 35

[dask]
workers = 4
threads_per_worker = 2
memory_limit = 2GB

[ollama]
max_loaded_models = 2
gpu_layers = 35
num_thread = 8
```

## üìû Suporte e Recursos

### Documenta√ß√£o Relacionada
- [Guia de Monitoramento](monitoring.md)
- [Troubleshooting](TROUBLESHOOTING.md)
- [Configura√ß√£o Avan√ßada](OPTIMIZATION.md)

### Ferramentas Externas
- [Dask Performance](https://docs.dask.org/en/latest/best-practices.html)
- [Ollama Performance](https://github.com/ollama/ollama/blob/main/docs/performance.md)
- [Docker Performance](https://docs.docker.com/config/containers/resource_constraints/)

---

**√öltima atualiza√ß√£o:** $(date +%Y-%m-%d)  
**Mantenedor:** Equipe Cluster AI
